{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:55.199024Z",
     "start_time": "2022-11-08T02:45:51.687725Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:55.599036Z",
     "start_time": "2022-11-08T02:45:55.199024Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "#总计20640个样本，每个样本8个属性表示，以及房价作为target，所有属性值均为number\n",
    "#目标变量：平均房屋价值\n",
    "#输入变量（特征）：平均收入、住房平均年龄、平均房间、平均卧室、人口、平均占用、纬度和经度\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:55.622930Z",
     "start_time": "2022-11-08T02:45:55.599036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:55.638947Z",
     "start_time": "2022-11-08T02:45:55.622930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:55.654944Z",
     "start_time": "2022-11-08T02:45:55.638947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:29:35.795544Z",
     "start_time": "2022-11-08T12:29:35.787542Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.where(input_tensor, a,b)：对于张量a，如果input_tensor对应位置的元素为True，则张量a中的该位置处元素保留，反之由张量b中相应位置的元素来代替。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:55.670919Z",
     "start_time": "2022-11-08T02:45:55.654944Z"
    }
   },
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1 \n",
    "    #判断，当误差的绝对值<1时loss为误差平方，>1时为线性的\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:55.935230Z",
     "start_time": "2022-11-08T02:45:55.670919Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "#输入每个房子的8个特征，预测其价格\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:57.644864Z",
     "start_time": "2022-11-08T02:45:55.935230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5417 - mae: 0.8956 - val_loss: 0.2505 - val_mae: 0.5390\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2102 - mae: 0.5048 - val_loss: 0.2095 - val_mae: 0.4958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ac568b780>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "#计算平均绝对误差MAE，使用自定义的huber损失\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存和加载包含自定义组件的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:57.684858Z",
     "start_time": "2022-11-08T02:45:57.644864Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:57.732738Z",
     "start_time": "2022-11-08T02:45:57.684858Z"
    }
   },
   "outputs": [],
   "source": [
    "#keras会保存模型名称，每次加载时需提供一个字典将函数名称映射到实际函数\n",
    "model=keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                              custom_objects={\"huber_fn\":huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:59.137269Z",
     "start_time": "2022-11-08T02:45:57.732738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2005 - mae: 0.4916 - val_loss: 0.1932 - val_mae: 0.4764\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1960 - mae: 0.4855 - val_loss: 0.1862 - val_mae: 0.4657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24accade518>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义误差阈值（1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:45:59.153273Z",
     "start_time": "2022-11-08T02:45:59.137269Z"
    }
   },
   "outputs": [],
   "source": [
    "#创建一个函数重新创建已配置的损失函数，阈值默认值为1.0\n",
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:00.707343Z",
     "start_time": "2022-11-08T02:45:59.153273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2174 - mae: 0.4853 - val_loss: 0.2231 - val_mae: 0.4748\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2118 - mae: 0.4785 - val_loss: 0.2115 - val_mae: 0.4622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24acebc17f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "#指定阈值为2.0\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:00.739301Z",
     "start_time": "2022-11-08T02:46:00.707343Z"
    }
   },
   "outputs": [],
   "source": [
    "#保存模型时不会保存阈值\n",
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载自定义损失的模型时必须指定其自定义loss的阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:00.867514Z",
     "start_time": "2022-11-08T02:46:00.739301Z"
    }
   },
   "outputs": [],
   "source": [
    "#加载时必须指定阈值，字典名称为为Keras命名的函数名称而非创建函数时的名称\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:02.228771Z",
     "start_time": "2022-11-08T02:46:00.867514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2098 - mae: 0.4752 - val_loss: 0.2417 - val_mae: 0.4734\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2071 - mae: 0.4705 - val_loss: 0.1993 - val_mae: 0.4526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24acc7d64e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义误差阈值（2）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kwargs将一个可变关键字参数的字典dict传给函数实参，参数列表长度可以为0或为其他值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:02.244778Z",
     "start_time": "2022-11-08T02:46:02.228771Z"
    }
   },
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    \n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        \"\"\"\n",
    "         接受**kwargs并将它们传递给父类构造函数，\n",
    "         其父类构造函数处理标准超参数：损失的name 和\n",
    "         用于聚合单个实例损失的reduction算法（默认为实例损失的总和）\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)#继承keras.losses.Loss类的初始化参数\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"获取标签和预测，计算所有实例loss，然后将其返回\"\"\"\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"使用keras.losses.Loss类的get_config()方法\n",
    "           保存新的超参数（自定义的loss的阈值）\n",
    "           返回一个字典，将每个超参数名称映射到其值\"\"\"\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:03.774028Z",
     "start_time": "2022-11-08T02:46:02.244778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8638 - mae: 1.0278 - val_loss: 0.2943 - val_mae: 0.5372\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2499 - mae: 0.5163 - val_loss: 0.2548 - val_mae: 0.5073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24acfde3f60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "#将阈值设置为2，使用HuberLoss类创建实例loss\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:03.846348Z",
     "start_time": "2022-11-08T02:46:03.774028Z"
    }
   },
   "outputs": [],
   "source": [
    "#保存模型时keras调用get_config()将配置以JSON格式保存到HDF5文件中\n",
    "#阈值会同时一起保存，加载时将类名映射到类本身即可\n",
    "model.save(\"my_model_with_a_custom_loss_class.h5\")\n",
    "\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:05.049591Z",
     "start_time": "2022-11-08T02:46:03.846348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2312 - mae: 0.4992 - val_loss: 0.2187 - val_mae: 0.4814\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2249 - mae: 0.4923 - val_loss: 0.2558 - val_mae: 0.4984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ad0fac4e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:05.073320Z",
     "start_time": "2022-11-08T02:46:05.049591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义激活函数、初始化、正则化、约束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 自定义激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:05.081784Z",
     "start_time": "2022-11-08T02:46:05.073780Z"
    }
   },
   "outputs": [],
   "source": [
    "#等同于keras.activations.softplus(z) 或 tf.nn.softplus(z)\n",
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义Glorot初始化"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "    shape: 输出张量的形状，必选\n",
    "    mean: 正态分布的均值，默认为0\n",
    "    stddev: 正态分布的标准差，默认为1.0\n",
    "    dtype: 输出的类型\n",
    "    seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样\n",
    "    name: 操作的名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:05.097785Z",
     "start_time": "2022-11-08T02:46:05.081784Z"
    }
   },
   "outputs": [],
   "source": [
    "#等同于keras.initializers.glorot_normal()\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)#正态初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义l1正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.reduce_sum ():按一定方式计算张量中元素之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:05.113817Z",
     "start_time": "2022-11-08T02:46:05.097785Z"
    }
   },
   "outputs": [],
   "source": [
    "#等同于keras.regularizers.l1(0.01)\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 确保权重均为正的自定义约束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.relu(features, name = None):计算激活函数 relu即 max(features, 0)\n",
    "\n",
    "tf.zeros_like（）：给定一个张量(tensor),返回所有元素都设置为零的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:05.129827Z",
     "start_time": "2022-11-08T02:46:05.113817Z"
    }
   },
   "outputs": [],
   "source": [
    "#等同于keras.contraints.nonneg():权重非负的约束\n",
    "#或tf.nn.relu(weights)\n",
    "def my_positive_weights(weights): \n",
    "    \"\"\"当权重＜0时将其设为0，当权重>=0时不变\"\"\"\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:05.145822Z",
     "start_time": "2022-11-08T02:46:05.129827Z"
    }
   },
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, \n",
    "                           activation=my_softplus,\n",
    "                           #激活函数应用于该层的输出，将结果传递给下一层\n",
    "                           \n",
    "                           kernel_initializer=my_glorot_initializer,\n",
    "                           #初始化层的权重\n",
    "                           \n",
    "                           kernel_regularizer=my_l1_regularizer,\n",
    "                           #训练过程中将权重传递给正则化函数计算正则化损失，\n",
    "                           #将其添加到主要损失中以得到最终loss\n",
    "                           \n",
    "                           kernel_constraint=my_positive_weights\n",
    "                           #在每个训练步骤后调用，将该层权重替换为约束权重\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T05:49:35.390338Z",
     "start_time": "2022-11-08T05:49:33.726518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6712 - mae: 0.8907 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6286 - mae: 0.5310 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ad5822a20>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape))\n",
    "model.add(layer)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "model.fit(X_train_scaled, y_train, epochs=2,validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:06.660924Z",
     "start_time": "2022-11-08T02:46:06.580747Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")\n",
    "\n",
    "#加载模型时指定自定义参数的字典\n",
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.abs():计算张量的绝对值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:06.676837Z",
     "start_time": "2022-11-08T02:46:06.660924Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    \"\"\"\n",
    "    用于l1正则化的普通类，\n",
    "    保存了超参数factor(控制L1权重衰减的程度)\n",
    "    \"\"\"\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, weights):\n",
    "        \"\"\"将权重与正则化参数相乘，并求和\"\"\"\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:06.692834Z",
     "start_time": "2022-11-08T02:46:06.676837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a= tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(tf.reduce_sum(a))#求得所有元素和21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:06.740841Z",
     "start_time": "2022-11-08T02:46:06.692834Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:08.196745Z",
     "start_time": "2022-11-08T02:46:06.740841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.9280 - mae: 0.9557 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6748 - mae: 0.5337 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ad323ce10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:46:08.268944Z",
     "start_time": "2022-11-08T02:46:08.196745Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")\n",
    "\n",
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
