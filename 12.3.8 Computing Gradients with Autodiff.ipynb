{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:00.498292Z","start_time":"2022-11-26T02:00:52.105880Z"},"id":"Ys3YEdz5DI_F"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:02.021615Z","start_time":"2022-11-26T02:01:00.498292Z"},"id":"aurOh7tuDI_L"},"outputs":[],"source":["from sklearn.datasets import fetch_california_housing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","housing = fetch_california_housing()\n","#总计20640个样本，每个样本8个属性表示，以及房价作为target，所有属性值均为number\n","#目标变量：平均房屋价值\n","#输入变量（特征）：平均收入、住房平均年龄、平均房间、平均卧室、人口、平均占用、纬度和经度\n","\n","X_train_full, X_test, y_train_full, y_test = train_test_split(\n","    housing.data, housing.target.reshape(-1, 1), random_state=42)\n","X_train, X_valid, y_train, y_valid = train_test_split(\n","    X_train_full, y_train_full, random_state=42)\n","\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_valid_scaled = scaler.transform(X_valid)\n","X_test_scaled = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:02.037537Z","start_time":"2022-11-26T02:01:02.021615Z"},"id":"BwzCTa42DI_M"},"outputs":[],"source":["input_shape = X_train.shape[1:]"]},{"cell_type":"markdown","metadata":{"id":"qUobys4VDI_M"},"source":["### 使用自动微分计算梯度"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:02.053287Z","start_time":"2022-11-26T02:01:02.037537Z"},"id":"qzZffAiZDI_M"},"outputs":[],"source":["def f(w1, w2):\n","    return 3 * w1 ** 2 + 2 * w1 * w2"]},{"cell_type":"markdown","metadata":{"id":"4KB6bHj_DI_M"},"source":["#### 通过在调整相应参数时测量函数输出的变化来计算每个偏导的近似值\n","\n","每个参数至少要调用一个f（）即计算一次f（w1，w2），对大型神经网络来说很繁琐"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:02.068604Z","start_time":"2022-11-26T02:01:02.054489Z"},"id":"yFZWJoBdDI_M","outputId":"90f113f0-8ffb-46aa-8328-8cedefb9ca12"},"outputs":[{"data":{"text/plain":["36.000003007075065"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["w1, w2 = 5, 3\n","eps = 1e-6\n","\n","(f(w1 + eps, w2) - f(w1, w2)) / eps#w1的梯度（函数关于w1的偏导:6*w1+2*w2的近似值）"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:02.084139Z","start_time":"2022-11-26T02:01:02.069488Z"},"id":"BItFcUZ2DI_M","outputId":"f2eaa5ae-2d68-40df-fd97-86d502017631"},"outputs":[{"data":{"text/plain":["10.000000003174137"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["(f(w1, w2 + eps) - f(w1, w2)) / eps#w2的梯度（函数关于w2的偏导:2*w1的近似值）"]},{"cell_type":"markdown","metadata":{"id":"YziglYjjDI_N"},"source":["### 自动微分\n","\n","结果准确（精度仅受浮点误差影响）\n","\n","无论有多少变量，gradient（）都只经历一次已经记录的计算（反向模式）"]},{"cell_type":"markdown","metadata":{"id":"wV5GfRHVDI_N"},"source":["#### tf.GradientTape():上下文，自动记录其涉及变量的每个操作。\n","默认只监控由tf.Variable创建的trainable=True属性的变量。"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.253073Z","start_time":"2022-11-26T02:01:02.085140Z"},"id":"6HpjzP0-DI_N"},"outputs":[],"source":["w1, w2 = tf.Variable(5.), tf.Variable(3.)\n","with tf.GradientTape() as tape:\n","    z = f(w1, w2)"]},{"cell_type":"markdown","metadata":{"id":"JVa7Xk85DI_N"},"source":["#### gradient()：求数值的梯度函数"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.268699Z","start_time":"2022-11-26T02:01:03.253073Z"},"id":"K4j9jKQtDI_N","outputId":"373713cd-86cc-4f8f-c5a9-415cd5dbfb6c"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n"," <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["gradients = tape.gradient(z, [w1, w2],unconnected_gradients='zero')\n","#针对两个变量[w1,w2]计算z的梯度\n","gradients\n","#w1的偏导:6*w1+2*w2=6*5.+2*3.=36.\n","#w2的偏导:2*w1=2*5.=10."]},{"cell_type":"markdown","metadata":{"id":"rVIs4M0sDI_N"},"source":["#### 调用tape的gradient（）方法后tape会立即被自动擦除"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.283924Z","start_time":"2022-11-26T02:01:03.270703Z"},"id":"cR3yHVORDI_N","outputId":"bdea7ba6-e88a-41e0-d39a-9cb1738212df"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(36.0, shape=(), dtype=float32)\n","A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"]}],"source":["#两次调用tape的gradient（）会报错\n","with tf.GradientTape() as tape:\n","    z = f(w1, w2)\n","    \n","dz_dw1 = tape.gradient(z, w1,unconnected_gradients='zero')\n","print(dz_dw1)\n","try:\n","    dz_dw2 = tape.gradient(z, w2,unconnected_gradients='zero')\n","except RuntimeError as ex:\n","    print(ex)"]},{"cell_type":"markdown","metadata":{"id":"Rf89SzdkDI_N"},"source":["#### 设置tape属性persistent=True可使得tape有持久性，但需在每次使用完该tape后将其删除以释放资源"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.300686Z","start_time":"2022-11-26T02:01:03.286437Z"},"id":"fWFSLZ0hDI_P"},"outputs":[],"source":["with tf.GradientTape(persistent=True) as tape:\n","    z = f(w1, w2)\n","\n","dz_dw1 = tape.gradient(z, w1,unconnected_gradients='zero')\n","dz_dw2 = tape.gradient(z, w2,unconnected_gradients='zero')\n","\n","del tape"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.316702Z","start_time":"2022-11-26T02:01:03.305683Z"},"id":"33jHycLFDI_P","outputId":"83a7c854-c794-4596-aee3-a19d480a4d31"},"outputs":[{"data":{"text/plain":["(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n"," <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["(dz_dw1,dz_dw2)"]},{"cell_type":"markdown","metadata":{"id":"kNk1809qDI_P"},"source":["#### tape仅跟踪涉及Variable变量的操作，针对tf.Variable变量以外的其他张量计算z梯度时,结果为None"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.334019Z","start_time":"2022-11-26T02:01:03.319689Z"},"id":"bv12glo8DI_P","outputId":"9d80f9f8-7459-4d0d-dda0-a41ce603636d"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n"," <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["c1, c2 = tf.constant(5.), tf.constant(3.)#创建张量tensor，类似Numpy的ndarray\n","with tf.GradientTape() as tape:\n","    z = f(c1, c2)\n","\n","gradients = tape.gradient(z, [c1, c2],unconnected_gradients='zero')\n","gradients"]},{"cell_type":"markdown","metadata":{"id":"msRWFpNyDI_P"},"source":["#### watch()可强制tape观察任何tensor，记录涉及他们的所有操作（可针对这些张量计算梯度，就像它们是变量一样）\n","\n","当需要实现正则化损失，以便在input变化不大时惩罚那些变化很大的激活时，损失将基于激活相对于输入的梯度而定。因此需要tape去观察不是变量的input。"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.349056Z","start_time":"2022-11-26T02:01:03.338024Z"},"id":"47TimJktDI_P","outputId":"d28c7412-30dc-49cb-ea4e-9093d105b7ef"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n"," <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["with tf.GradientTape() as tape:\n","    tape.watch(c1)\n","    tape.watch(c2)\n","    z = f(c1, c2)\n","\n","gradients = tape.gradient(z, [c1, c2],unconnected_gradients='zero')\n","gradients"]},{"cell_type":"markdown","metadata":{"id":"kvpqxvVcDI_Q"},"source":["#### 计算向量的梯度(如包含多个损失的向量）时，tf将计算向量和的梯度"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.365017Z","start_time":"2022-11-26T02:01:03.351021Z"},"id":"8hmI5BaIDI_Q","outputId":"642f682b-e447-4aa0-8652-499db508851a"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n"," <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["with tf.GradientTape() as tape:\n","    z1 = f(w1, w2 + 2.)\n","    z2 = f(w1, w2 + 5.)\n","    z3 = f(w1, w2 + 7.)\n","\n","tape.gradient([z1, z2, z3], [w1, w2],unconnected_gradients='zero')"]},{"cell_type":"markdown","metadata":{"id":"-osBWHrUDI_Q"},"source":["#### tf.stack()：矩阵拼接"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.396057Z","start_time":"2022-11-26T02:01:03.367020Z"},"id":"3tUmsMyiDI_Q","outputId":"a99a3154-6b64-49cf-83f8-0d37ea712156"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2,), dtype=float32, numpy=array([136.,  30.], dtype=float32)>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["with tf.GradientTape(persistent=True) as tape:\n","    z1 = f(w1, w2 + 2.)\n","    z2 = f(w1, w2 + 5.)\n","    z3 = f(w1, w2 + 7.)\n","\n","tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2],unconnected_gradients='zero') \n","                        for z in (z1, z2, z3)]), axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.412121Z","start_time":"2022-11-26T02:01:03.398019Z"},"id":"TWkSiBIgDI_Q"},"outputs":[],"source":["del tape"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2022-11-17T05:38:47.462886Z","start_time":"2022-11-17T05:38:47.447762Z"},"id":"rmBHyY1TDI_Q"},"source":["#### 计算向量的梯度时tf将计算向量和的梯度，需要获得单独梯度时需调用tape的jacobian（）:使用磁带上下文中记录的操作计算jacobian"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.648134Z","start_time":"2022-11-26T02:01:03.414018Z"},"id":"-TK-WzDkDI_Q","outputId":"cb46d694-a07e-4c76-f3bf-25d0ecc7ec51"},"outputs":[{"name":"stdout","output_type":"stream","text":["res: tf.Tensor(\n","[[[[48.  0.]\n","   [ 0.  0.]]\n","\n","  [[ 0. 12.]\n","   [ 0.  0.]]]\n","\n","\n"," [[[ 0.  0.]\n","   [ 3.  0.]]\n","\n","  [[ 0.  0.]\n","   [ 0. 27.]]]], shape=(2, 2, 2, 2), dtype=float32)\n"]}],"source":["x = tf.constant([[4, 2],[1, 3]], dtype=tf.dtypes.float32) \n","  \n","with tf.GradientTape() as gfg:\n","    gfg.watch(x) \n","    y = x * x * x \n","res  = gfg.jacobian(y, x)  \n","print(\"res:\",res)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.664126Z","start_time":"2022-11-26T02:01:03.650020Z"},"id":"2sLCZki3DI_Q"},"outputs":[],"source":["#求二阶导hessian\n","with tf.GradientTape(persistent=True) as hessian_tape:\n","    with tf.GradientTape() as jacobian_tape:\n","        z = f(w1, w2)\n","    jacobians = jacobian_tape.gradient(z, [w1, w2],unconnected_gradients='zero')\n","hessians = [hessian_tape.gradient(jacobian, [w1, w2],unconnected_gradients='zero')\n","            for jacobian in jacobians]\n","del hessian_tape"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.680019Z","start_time":"2022-11-26T02:01:03.667021Z"},"id":"7vWQB78JDI_R","outputId":"864490a2-0949-4046-b4c2-c058933fb028"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n"," <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["jacobians\n","#w1的偏导:6*w1+2*w2=6*5.+2*3.=36.\n","#w2的偏导:2*w1=2*5.=10."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.695021Z","start_time":"2022-11-26T02:01:03.683024Z"},"id":"5g1Oap8aDI_R","outputId":"3cc8ee84-037d-47c3-d986-5bfe71534ef1"},"outputs":[{"data":{"text/plain":["[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n","  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n"," [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>,\n","  <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["hessians\n","#w1的偏导:6*w1+2*w2；w1的二阶导：6.，w1的偏导对w2的偏导：2.\n","#w2的偏导:2*w1=2*5.=10.；w2的偏导对w1的偏导：2."]},{"cell_type":"markdown","metadata":{"id":"tnyRm-hwDI_R"},"source":["#### tf.stop_gradient（）：用于阻止梯度在神经网络的某些部分反向传播\n","\n","在前向传递过程中返回其输入，在反向传播期间不让梯度通过（作用类似于常量）"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.710056Z","start_time":"2022-11-26T02:01:03.697024Z"},"id":"_xxfjr9qDI_R","outputId":"0f60049b-5a21-4841-8762-048bab05ca97"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>,\n"," <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["def f(w1, w2):\n","    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n","\n","with tf.GradientTape() as tape:\n","    z = f(w1, w2)\n","\n","tape.gradient(z, [w1, w2],unconnected_gradients='zero')#[tensor 30.,None]\n","#w1的偏导：6*w1+None=6*5.=30.\n","#w2的偏导：0+None=0"]},{"cell_type":"markdown","metadata":{"id":"DfSgJvuxDI_R"},"source":["大数值输入来计算my_softplus（）的梯度结果为Nan，因为autodiff计算此函数的梯度时由于浮点精度误差，最终导致精度无穷除以无穷"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.726057Z","start_time":"2022-11-26T02:01:03.712017Z"},"id":"HPeRTKZrDI_R","outputId":"afb59806-d9f4-4508-9320-012517d6b053"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["def my_softplus(z): # return value is just tf.nn.softplus(z)\n","    return tf.math.log(tf.exp(z) + 1.0)\n","\n","x = tf.Variable(100.)\n","with tf.GradientTape() as tape:\n","    z = my_softplus(x)\n","\n","tape.gradient(z, [x])"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.742015Z","start_time":"2022-11-26T02:01:03.728017Z"},"id":"t9GcD47sDI_R","outputId":"ea6e859e-abaa-4f44-a053-aa7d7c136736"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["x = tf.Variable([100.])\n","with tf.GradientTape() as tape:\n","    z = my_softplus(x)\n","\n","tape.gradient(z, [x])"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.758016Z","start_time":"2022-11-26T02:01:03.744019Z"},"id":"y_gipdNWDI_S","outputId":"0e8e3359-6494-4e7e-ec70-1a406297a269"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor([1.], shape=(1,), dtype=float32)\n"]},{"data":{"text/plain":["(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([inf], dtype=float32)>,\n"," [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["#较大输入值也可获得正确结果，但主要输出仍然会爆炸\n","@tf.custom_gradient\n","#修饰my_softplus()函数的梯度的计算，使它返回其正常输出又返回计算导数的函数\n","def my_better_softplus(z):\n","    exp = tf.exp(z)\n","    def my_softplus_gradients(grad):\n","        print(grad)#1.\n","        return grad / (1 + 1 / exp)#softplus函数的导数，在数值上稳定\n","    return tf.math.log(exp + 1), my_softplus_gradients\n","            #softplus函数（爆炸了）、优化的梯度(softplus的倒数)\n","\n","x = tf.Variable([1000.])\n","with tf.GradientTape() as tape:\n","    z = my_better_softplus(x)\n","\n","z, tape.gradient(z, [x])"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-11-26T02:01:03.774027Z","start_time":"2022-11-26T02:01:03.760018Z"},"id":"7mURRZAVDI_S","outputId":"f6632aab-7aa0-4003-e5f3-03f3a047efbc"},"outputs":[{"data":{"text/plain":["(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n"," [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["#在输入较大时返回输入\n","def my_better_softplus(z):\n","    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))\n","\n","x = tf.Variable([1000.])\n","with tf.GradientTape() as tape:\n","    z = my_better_softplus(x)\n","\n","z, tape.gradient(z, [x])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhc76R1jDI_V"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}